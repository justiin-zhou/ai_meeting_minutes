# 会议助手服务 - 需求文档

## 文档信息
- **项目名称**: 会议助手服务 (Meeting Assistant Service)
- **文档版本**: v1.0
- **创建日期**: 2025-10-15
- **文档类型**: 需求明确文档
- **工作流阶段**: 1/3 - 需求明确

---

## 1. 项目概述

### 1.1 项目背景
在日常工作中，会议是重要的沟通和决策场景。会议结束后，往往需要整理会议纪要、提取关键信息、回顾会议内容等。传统的人工整理方式耗时费力，且容易遗漏重要信息。本项目旨在利用大语言模型技术，自动化处理会议转写内容，提供智能化的会议纪要生成和问答服务。

### 1.2 项目目标
- **主要目标**: 提供基于大语言模型的会议内容处理服务，支持自动生成会议纪要和智能问答
- **次要目标**: 
  - 支持多种LLM提供商，提供灵活的模型选择
  - 提供流式和非流式两种响应模式，满足不同应用场景
  - 实现会议内容缓存机制，提升响应速度和用户体验

### 1.3 目标用户
- **开发者**: 需要集成会议处理能力的应用开发者
- **企业用户**: 需要会议管理和知识沉淀的企业组织
- **个人用户**: 需要会议记录和回顾的个人用户

---

## 2. 功能需求

### 2.1 核心功能

#### FR-001: 会议纪要生成
**优先级**: P0（必须实现）

**功能描述**:
- 接收会议转写文本（SRT格式），自动生成结构化的会议纪要
- 纪要内容应包括：会议主题、主要讨论内容、关键决策、行动项等
- 支持流式和非流式两种返回模式

**输入**:
- `log_id`: 日志追踪ID（字符串）
- `srt_text`: SRT格式的会议转写文本（字符串）
- `meeting_id`: 会议唯一标识符（字符串）
- `stream`: 是否采用流式返回（布尔值）

**输出**:
- 流式模式：逐步返回生成的纪要内容，每个数据块包含 `answer`（文本片段）和 `is_end`（是否结束）
- 非流式模式：一次性返回完整的会议纪要

**验收标准**:
- [ ] 能够正确解析SRT格式文本
- [ ] 生成的纪要包含会议主题、讨论内容、决策和行动项
- [ ] 流式和非流式模式均能正常工作
- [ ] 生成的纪要自动缓存，以 `meeting_id` 为键

#### FR-002: 会议智能问答
**优先级**: P0（必须实现）

**功能描述**:
- 基于会议内容和纪要，回答用户关于会议的问题
- 支持多轮对话，维护对话上下文
- 支持流式和非流式两种返回模式

**输入**:
- `log_id`: 日志追踪ID（字符串）
- `srt_text`: SRT格式的会议转写文本（字符串）
- `meeting_id`: 会议唯一标识符（字符串）
- `messages`: 对话历史列表（包含 role 和 content）
- `stream`: 是否采用流式返回（布尔值）

**输出**:
- 流式模式：逐步返回回答内容
- 非流式模式：一次性返回完整回答

**验收标准**:
- [ ] 能够基于会议纪要和原文回答问题
- [ ] 支持多轮对话，能够理解上下文
- [ ] 当信息不足时，能够如实告知用户
- [ ] 流式和非流式模式均能正常工作

#### FR-003: SRT文本解析
**优先级**: P0（必须实现）

**功能描述**:
- 解析SRT字幕格式文本，提取纯文本内容
- 过滤时间轴、序号等非内容信息

**输入**:
- SRT格式的字幕文本

**输出**:
- 提取后的纯文本内容

**验收标准**:
- [ ] 能够正确解析标准SRT格式
- [ ] 自动过滤序号行和时间轴行
- [ ] 保留文本内容的原始顺序

#### FR-004: 会议内容缓存
**优先级**: P1（重要）

**功能描述**:
- 以 `meeting_id` 为键，缓存会议纪要和原文
- 问答功能优先使用缓存的纪要，避免重复生成
- 提升响应速度和降低API调用成本

**验收标准**:
- [ ] 首次调用 `/summary` 时生成并缓存纪要
- [ ] `/chat` 接口能够使用缓存的纪要
- [ ] 缓存未命中时能够自动生成纪要

### 2.2 系统功能

#### FR-005: 健康检查
**优先级**: P1（重要）

**功能描述**:
- 提供服务健康状态检查接口
- 返回服务状态和缓存统计信息

**验收标准**:
- [ ] 能够返回服务运行状态
- [ ] 能够返回当前缓存的会议数量

#### FR-006: LLM提供商支持
**优先级**: P0（必须实现）

**功能描述**:
- 支持多种LLM提供商，包括百度千帆和DeepSeek
- 通过配置切换不同的LLM提供商
- 提供统一的LLM调用接口

**验收标准**:
- [ ] 支持百度千帆（ERNIE系列模型）
- [ ] 支持DeepSeek（deepseek-chat、deepseek-coder）
- [ ] 支持通过环境变量切换提供商
- [ ] 统一的流式和非流式调用接口

---

## 3. 非功能需求

### 3.1 性能需求

#### NFR-001: 响应时间
- **流式响应**: 首字延迟 < 3秒
- **非流式响应**: 总响应时间 < 30秒（中等长度会议）
- **健康检查**: 响应时间 < 100ms

#### NFR-002: 并发处理
- 支持至少 10 个并发请求
- 建议使用 Gunicorn 等生产级WSGI服务器

#### NFR-003: 可用性
- 服务可用性目标: 99%
- 提供优雅的错误处理和降级方案

### 3.2 安全需求

#### NFR-004: API密钥管理
- API密钥通过环境变量配置，不得硬编码
- 支持 `.env` 文件加载环境变量

#### NFR-005: 输入验证
- 所有API接口必须验证必填参数
- 对异常输入提供友好的错误提示

### 3.3 可维护性需求

#### NFR-006: 日志记录
- 记录所有请求的关键信息（log_id、meeting_id、操作类型）
- 记录错误堆栈信息，便于问题排查
- 支持可配置的日志级别（DEBUG、INFO、WARNING、ERROR）

#### NFR-007: 代码规范
- 遵循PEP 8 Python代码规范
- 函数和类提供清晰的文档字符串
- 关键逻辑添加注释

### 3.4 部署需求

#### NFR-008: 容器化支持
- 提供 Dockerfile 支持容器化部署
- 提供 docker-compose.yml 支持一键启动

#### NFR-009: 环境兼容性
- 支持 Python 3.8 及以上版本
- 支持 Linux、macOS、Windows 操作系统

---

## 4. 接口需求

### 4.1 API接口规范

#### API-001: POST /summary
**功能**: 生成会议纪要

**请求格式**:
```json
{
  "log_id": "string",
  "srt_text": "string",
  "meeting_id": "string",
  "stream": boolean
}
```

**响应格式**:
- 流式响应（每行一个JSON）:
```json
{"status": 200, "data": {"answer": "文本片段", "is_end": 0}}
{"status": 200, "data": {"answer": "", "is_end": 1}}
```

- 非流式响应:
```json
{
  "status": 200,
  "data": {
    "answer": "完整的会议纪要",
    "is_end": 1
  }
}
```

#### API-002: POST /chat
**功能**: 会议智能问答

**请求格式**:
```json
{
  "log_id": "string",
  "srt_text": "string",
  "meeting_id": "string",
  "messages": [
    {
      "role": "user",
      "content": "问题内容"
    }
  ],
  "stream": boolean
}
```

**响应格式**: 同 `/summary` 接口

#### API-003: GET /health
**功能**: 健康检查

**响应格式**:
```json
{
  "status": "ok",
  "cached_meetings": 5
}
```

### 4.2 数据格式规范

#### SRT格式示例
```
1
00:00:01,000 --> 00:00:03,000
你好，世界！

2
00:00:04,500 --> 00:00:06,000
这是第二行字幕。
```

#### 对话历史格式
```json
{
  "messages": [
    {
      "role": "user",
      "content": "你好"
    },
    {
      "role": "assistant",
      "content": "你好！有什么可以帮助你的吗？"
    }
  ]
}
```

---

## 5. 约束条件

### 5.1 技术约束
- 必须使用 Python 3.8 或更高版本
- 必须使用 Flask 作为 Web 框架
- 必须支持至少一种LLM提供商（千帆或DeepSeek）

### 5.2 业务约束
- 需要用户自行提供LLM API密钥
- 当前版本使用内存缓存，服务重启后缓存清空
- SRT文本格式必须符合标准规范

### 5.3 成本约束
- 优先使用开源和免费的技术栈
- 通过缓存机制减少LLM API调用次数，降低成本

---

## 6. 验收标准

### 6.1 功能验收
- [ ] 所有P0优先级功能完全实现
- [ ] 所有P1优先级功能完全实现
- [ ] 提供完整的测试脚本

### 6.2 性能验收
- [ ] 流式响应首字延迟 < 3秒
- [ ] 健康检查响应时间 < 100ms
- [ ] 支持10个并发请求

### 6.3 质量验收
- [ ] 代码通过静态检查（无严重警告）
- [ ] 提供完整的使用文档
- [ ] 提供快速开始指南和示例代码

---

## 7. 风险识别

### 7.1 技术风险
- **风险**: LLM API可能出现不稳定或限流
  - **缓解措施**: 实现错误处理和重试机制，提供降级方案

- **风险**: 内存缓存在高并发场景下可能导致内存溢出
  - **缓解措施**: 实现LRU缓存策略，设置缓存大小上限

### 7.2 业务风险
- **风险**: 不同LLM提供商的返回质量可能不一致
  - **缓解措施**: 提供模型切换指南，建议用户测试后选择合适的模型

---

## 8. 未来规划

### 8.1 短期规划（1-3个月）
- 支持Redis等持久化缓存方案
- 增加API限流和鉴权功能
- 优化Prompt，提升纪要生成质量

### 8.2 长期规划（3-6个月）
- 支持更多LLM提供商（如OpenAI、Anthropic）
- 支持会议音频直接转写
- 提供会议摘要导出功能（PDF、Word等格式）
- 实现会议知识库功能，支持跨会议检索

---

## 9. 附录

### 9.1 术语表
- **SRT**: SubRip Text，一种常见的字幕文件格式
- **LLM**: Large Language Model，大语言模型
- **千帆**: 百度智能云千帆大模型平台
- **DeepSeek**: 深度求索开源大语言模型
- **流式响应**: 逐步返回生成内容，而非等待全部生成完成

### 9.2 参考资料
- [Flask官方文档](https://flask.palletsprojects.com/)
- [百度千帆大模型平台](https://cloud.baidu.com/product/wenxinworkshop)
- [DeepSeek开放平台](https://platform.deepseek.com/)
- [SRT格式规范](https://en.wikipedia.org/wiki/SubRip)

---

**文档状态**: ✅ 已完成
**下一步**: 进入架构设计阶段

